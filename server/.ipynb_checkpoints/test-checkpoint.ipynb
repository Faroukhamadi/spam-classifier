{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26d24710",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import tarfile\n",
    "import re\n",
    "import email\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21755124",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOAD_ROOT = 'https://spamassassin.apache.org/old/publiccorpus/'\n",
    "SPAM_PATHS = [\n",
    "    '20021010_easy_ham.tar.bz2',\n",
    "    '20021010_hard_ham.tar.bz2',\n",
    "    '20021010_spam.tar.bz2',\n",
    "    '20030228_easy_ham.tar.bz2',\n",
    "    '20030228_easy_ham_2.tar.bz2',\n",
    "    '20030228_hard_ham.tar.bz2',\n",
    "    '20030228_spam.tar.bz2',\n",
    "    '20030228_spam_2.tar.bz2',\n",
    "    '20050311_spam_2.tar.bz2',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e093425",
   "metadata": {},
   "source": [
    "### Concatenating all datasets might not work!! Too much data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0532bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_spam_data(download_root=DOWNLOAD_ROOT, spam_paths=SPAM_PATHS):\n",
    "    if not os.path.isdir('data'):\n",
    "        os.makedirs('data')\n",
    "    for path in SPAM_PATHS:\n",
    "        url = DOWNLOAD_ROOT + path\n",
    "        tgz_path = os.path.join('data', path)\n",
    "        urllib.request.urlretrieve(url, tgz_path)\n",
    "        spam_tgz = tarfile.open(tgz_path)\n",
    "        spam_tgz.extractall(path='data')\n",
    "    spam_tgz.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de89fd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_spam_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b67725b",
   "metadata": {},
   "source": [
    "### One spam example + one ham example should do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f6103dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    ham_path = os.path.join(os.getcwd(), 'data', 'easy_ham_2')\n",
    "    spam_path = os.path.join(os.getcwd(), 'data', 'spam_2')\n",
    "    \n",
    "    x_spam = []\n",
    "    x_ham = []\n",
    "    \n",
    "    for filename in os.listdir(ham_path):\n",
    "        abs_path = os.path.join(ham_path, filename)\n",
    "        with open(abs_path, 'r', encoding='utf8', errors='ignore') as f:\n",
    "            x_ham.append(f.read())\n",
    "\n",
    "    for filename in os.listdir(spam_path):\n",
    "        abs_path = os.path.join(spam_path, filename)\n",
    "        with open(abs_path, 'r', encoding='utf8', errors='ignore') as f:\n",
    "            x_spam.append(f.read())\n",
    "            \n",
    "    return np.array(x_spam, dtype='object'), np.array(x_ham, dtype='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b82793e",
   "metadata": {},
   "source": [
    "## Warning! Don't use the function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "598d50aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_all_data():\n",
    "    \"\"\"\n",
    "    If OpenAI ever wants to test their TPUs, this is a good place to start.\n",
    "    Not feasible on a normal computer though :(\n",
    "    \"\"\"\n",
    "    x_spam = []\n",
    "    x_ham = []\n",
    "    path = os.path.join(os.getcwd(), 'data')\n",
    "    for dirname in os.listdir(path):\n",
    "        if 'tar' not in dirname:\n",
    "            if 'spam' in dirname:\n",
    "                for filename in os.listdir(os.path.join(path, dirname)):\n",
    "                    abs_path = os.path.join(path, dirname, filename)\n",
    "                    with open(abs_path, 'rb') as f:\n",
    "                        x_spam.append(f.read().split())\n",
    "            else:\n",
    "                for filename in os.listdir(os.path.join(path, dirname)):\n",
    "                    abs_path = os.path.join(path, dirname, filename)\n",
    "                    with open(abs_path, 'rb') as f:\n",
    "                        x_ham.append(f.read().split())\n",
    "    return np.array(x_spam), np.array(x_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f9302e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_spam, x_ham = load_data()\n",
    "y_spam = np.ones(x_spam.shape)\n",
    "y_ham = np.zeros(x_ham.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37ea0aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.concatenate([x_spam, x_ham])\n",
    "y = np.concatenate([y_spam, y_ham])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb33ede7",
   "metadata": {},
   "source": [
    "##### Define a custom preprocessing steps to convert to lowercase and remove: \n",
    "- URLs\n",
    "- Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d76f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa99384c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e49a570e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for train_index, test_index in sss.split(x, y):\n",
    "    x_train, x_test = x[train_index], x[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "555a7056",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strip_headers=False, convert_lower=True):\n",
    "        self.strip_headers = strip_headers\n",
    "        self.convert_lower = convert_lower\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_out = np.empty((x.shape), dtype=x.dtype)\n",
    "        for i, e in enumerate(x):\n",
    "            print(e)\n",
    "            msg = email.message_from_string(e)\n",
    "\n",
    "            if self.strip_headers:\n",
    "                for k in msg.keys():\n",
    "                    del msg[k]\n",
    "\n",
    "                    \n",
    "            payload = msg.get_payload()\n",
    "            \n",
    "            if self.convert_lower:\n",
    "                if isinstance(payload, list):\n",
    "                    payload_str = ''.join(p.as_string().lower() for p in payload)\n",
    "                    msg.set_payload(payload_str)\n",
    "                else:\n",
    "                    msg.set_payload(msg.get_payload().lower())\n",
    "            \n",
    "            x_out[i] = msg.as_string()\n",
    "\n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "585c87b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailReplacer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, replace_url=False, replace_number=False):\n",
    "        self.replace_url = replace_url\n",
    "        self.replace_number = replace_number\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_out = np.empty((x.shape), dtype=x.dtype)\n",
    "        \n",
    "        for i, e in enumerate(x):\n",
    "            if isinstance(e, bytes):\n",
    "                e = e.decode('ISO-8859-1')\n",
    "                \n",
    "            if self.replace_url:\n",
    "                e = re.sub(r'http\\S+|www\\S+', 'URL', e)\n",
    "            \n",
    "            if self.replace_number:\n",
    "                e = re.sub(r'\\d+', 'NUMBER', e)\n",
    "                \n",
    "            e = e.lower()\n",
    "            \n",
    "            x_out[i] = e\n",
    "        \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29fefddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmailStemmer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, use_porter=False):\n",
    "        self.use_porter = use_porter\n",
    "        \n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, x):\n",
    "        x_out = np.empty((x.shape), dtype=x.dtype)\n",
    "\n",
    "        for i, e in enumerate(x):\n",
    "            if self.use_porter:\n",
    "                x_out[i] = SnowballStemmer('porter').stem(e)\n",
    "            else:\n",
    "                x_out[i] = SnowballStemmer('english').stem(e)\n",
    "                \n",
    "        return x_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac87a0e",
   "metadata": {},
   "source": [
    "##### Don't use this ðŸ”«"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91c4dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is useless since we have CountVectorizer\n",
    "class TransformBOW(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        vectorizer = CountVectorizer(encoding='ISO-8859-1')\n",
    "        x_bow_sparse = vectorizer.fit_transform(x)\n",
    "        x_bow = x_bow_sparse.toarray()\n",
    "        return x_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca30871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(EmailTransformer(), EmailReplacer(replace_number=True, replace_url=True), EmailStemmer(), verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d46c7638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] .. (step 1 of 3) Processing emailtransformer, total=   4.4s\n",
      "[Pipeline] ..... (step 2 of 3) Processing emailreplacer, total=   0.4s\n",
      "[Pipeline] ...... (step 3 of 3) Processing emailstemmer, total=   1.4s\n"
     ]
    }
   ],
   "source": [
    "x_tr = pipeline.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e07b879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(encoding=&#x27;ISO-8859-1&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(encoding=&#x27;ISO-8859-1&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer(encoding='ISO-8859-1')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(encoding='ISO-8859-1')\n",
    "vectorizer.fit(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98a1cd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tr = pipeline.transform(x_train)\n",
    "x_test_tr = pipeline.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "362b8fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tr = vectorizer.transform(x_train_tr)\n",
    "x_test_tr = vectorizer.transform(x_test_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65e2bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ecc1a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GradientBoostingClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb = GradientBoostingClassifier()\n",
    "gb.fit(x_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67adad98",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gb.predict(x_test_tr)\n",
    "score = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c81475dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9857142857142858"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a2bfcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = 'From bruces@yami.57thstreet.com  Tue Aug  6 23:43:54 2002\\nReturn-Path: <bruces@yami.57thstreet.com>\\nDelivered-To: yyyy@localhost.netnoteinc.com\\nReceived: from localhost (localhost [127.0.0.1])\\n\\tby phobos.labs.netnoteinc.com (Postfix) with ESMTP id E7763440A8\\n\\tfor <jm@localhost>; Tue,  6 Aug 2002 18:43:53 -0400 (EDT)\\nReceived: from phobos [127.0.0.1]\\n\\tby localhost with IMAP (fetchmail-5.9.0)\\n\\tfor jm@localhost (single-drop); Tue, 06 Aug 2002 23:43:53 +0100 (IST)\\nReceived: from yami.57thstreet.com ([66.100.224.110]) by\\n    dogma.slashnull.org (8.11.6/8.11.6) with SMTP id g76MiNk21740 for\\n    <jm@jmason.org>; Tue, 6 Aug 2002 23:44:24 +0100\\nReceived: (qmail 18139 invoked by uid 1045); 6 Aug 2002 22:40:55 -0000\\nDate: 6 Aug 2002 22:40:55 -0000\\nMessage-Id: <20020806224055.18137.qmail@yami.57thstreet.com>\\nFrom: Bruce Sterling <bruces@well.com>\\nTo: yyyy@spamassassin.taint.org\\nSubject: Viridian Note 00326:  Air-Conditioned Tokyo\\n\\nKey concepts:  Tokyo, urban overheating,\\nclimate change remediation\\n\\nAttention Conservation Notice: a weird,\\nhand-waving Nipponese mega-scheme.\\n\\nLinks:\\nhttp://http://www.viridiandesign.org/products/furniture.htm\\nFrom:Laurence Aurbach <translucent*spamcop.net?>\\nSubject:Viridian Furniture List\\n\\nThe Viridian Furniture List is now online in the \\n\"Recommended Products\" section of the Viridian website. \\nDavid Bergman did a yeoman-like job assembling this list \\nand adding comments. He\\'s also mirroring the list on his \\nown furniture site, Fire and Water.\\nhttp://cyberg.com/fw/ecofurn.htm \\n\\nMaybe you\\'ll find a woven bamboo buffet or a biopolymer \\nmesh coffee table. == L.J. Aurbach\\n\\n\\n---------------------------------------------------\\nEntries in the Global Civil Society Design Contest.\\n\\nFrom: Steven W. Schuldt <swschuldt*mac.com>\\nhttp://www.americanrobotz.com/images2/Soon_GlobalCivilSocietyLaptop.jpg\\n\\nFrom: Ben Davis <bend*earthlink.net>\\nhttp://www.digitaleverything.com/GlobalComputer.htm\\n\\nFrom: Joerg F. Wittenberger <Joerg.Wittenberger*pobox.com>\\nhttp://www.askemos.org/ \\nhttp://www.askemos.org:9080/RomePaper.pdf\\n\\nFrom: Scott Vandehey <scot*spaceninja.com >\\nhttp://spaceninja.com/viridian/notebook.html\\n\\nFrom: Bob Morris <bob*bomoco.com>\\nhttp://viridianrepository.com/GlobalCivil/\\n\\nFrom: Anonymous\\nhttp://home.freiepresse.de/befis/zx2000.html\\nhttp://apollo.spaceports.com/~bodo4all/zx/zx97.htm\\nhttp://www.vkb.co.il/\\n\\nFrom: Jim Thompson <jim*musenki.com>\\nhttp://www.simputer.org\\nhttp://www.cnn.com/2002/TECH/ptech/07/05/india.simputer.reut/index.html\\n\\nFrom: Mike Rosing <eresrch*eskimo.com>\\nhttp://www.eskimo.com/~eresrch/viridian\\n\\nFrom: Till Westermayer <till*tillwe.de>\\nhttp://www.westermayer.de/till/projekte/02gcsdl.htm\\n\\nFrom:Duncan Stewart <stewarts*stewarts.org?>\\nhttp://www.stewarts.org/viridian/GCS\\n\\nFrom: R. Charles Flickinger <idlewild*mac.com>\\nhttp://homepage.mac.com/iHUG/GCS2000.html\\n\\nFrom:\"Kevin Prichard\" <kevin*indymedia.org>\\n\\n\"I  nominate Rop Gonggrijp\\'s Secure Notebook, which was \\nshown recently at H2K2. (http://www.h2k2.net).\\n\\nhttp://www.nah6.com/\\nhttp://www.nah6.com/nah6-h2k2_files/v3_document.html\\n\\n\"The premise is both important and hilarious. The Secure \\nNotebook provides a Secure Windows XP installation. \\nWindows has a long history of being secure neither from \\nattack nor privacy incursion, so this is something. \\n\\n\"Nothing gets in and nothing gets out, without it being \\nfirewalled,  filtered, proxied, and encrypted. How is this \\ndone? A modified Debian  Linux boots first, running custom \\nNAH6 crypto device drivers, and then  boots XP within \\nvmware.\"\\n\\nSincerely yours, \\nKevin Prichard \\nkevin*indymedia.org\\n\\nThis contest expires in nine days:  August 15, 2002. \\n----------------------------------------------------\\n\\nSource: Planet Ark\\n\\nhttp://www.planetark.org/dailynewsstory.cfm/newsid/17160/story.htm\\n\\n\"Cooler Tokyo summers may be just a pipe dream away\\nby Elaine Lies\\n\\nJAPAN: August 5, 2002\\n\\n   \"TOKYO == In what could be the ultimate in public works \\nprojects, a Japanese panel of experts has proposed \\nrelieving the misery of steamy Tokyo summers by cooling \\nthe huge city with sea water and a labyrinth of \\nunderground pipes. \\n\\n   \"Though summers are hard in any city, Tokyo\\'s narrow \\nstreets, hordes of people and clusters of massive \\nskyscrapers, largely unrelieved by greenery, produce a \\nspecial brand of discomfort.\\n\\n   \"And it gets worse every year.  (((Oh yeah.  You bet it \\ndoes.))) The number of nights when temperatures stay above \\n25 Celsius (77 Fahrenheit) in Tokyo has doubled over the \\nlast 30 years, while average temperatures have shot up by \\n2.9 degrees C over the last century. Relief, however \\ndistant, could be on the way.  (((\"Great news, weather \\nsufferers!  We live in the high-tech capital of a G-7 \\nstate!\")))\\n\\n   \"At the behest of the Construction Ministry, the panel \\nhas drawn up a plan that would use a network of buried \\npipes, and water pumped from the sea, to cool things down. \\n\\'In the very best conditions, certain areas could in \\ntheory become as much as 2.6 degrees Celsius cooler,\\' said \\nYujin Minobe, a ministry planner.\\n\\n    \"The huge air-conditioning systems currently used to \\ncool buildings get rid of the heat they take out of the \\nstructure by venting it into the outside air, raising \\ntemperatures still further and creating a \\'heat island\\' \\nphenomenon in large cities.  (((Soon whole *cities* will \\ndo it and vent their heat straight into the rising seas! \\nLook out, Antarctica.)))\\n\\n    \"Under the plan, this heat would be transferred to \\nwater in large underground tanks, and the water then \\npumped through a six-km (3.7-mile) network of underground \\npipes to a cooling plant on the Tokyo waterfront.\\n\\n    \"There the heat from this water would be transferred \\nto cooler sea water before the then-cooled water was \\npumped back through the underground pipes. The sea water, \\nnow warmed, would be released into the waters of Tokyo \\nBay.\\n\\n    \"COSTLY PLAN.  (((That\\'s unsurprising.)))  Minobe said \\nthe plan would cover some 123 hectares (304 acres) in the \\ncentre of Tokyo, including the Marunouchi business \\ndistrict and the posh Ginza shopping area, and would \\ninitially cost around 41 billion yen ($344 million).\\n\\n    \"\\'Savings on reduced energy usage would eventually \\nhelp pay for this,\\' he said.  (((A real nest of ironies \\nhere, folks.))) Officials quoted in the English-language \\nJapan Times said energy savings would total more than 1 \\nbillion yen a year, meaning the system would pay for \\nitself in a bit over 30 years.\\n\\n    \"However, Minobe said many problems remained with the \\nplan, which has only been under discussion since April \\nlast year. One of the most serious problems is whether \\nwarmer water being returned to Tokyo Bay would damage the \\nfragile marine ecosystem, a point Minobe said still \\nrequired more study.  (((Give it 30 years and there won\\'t \\nbe any ecosystem left to study.)))\\n\\n    \"He said the average temperature cut is likely to be \\nonly around 0.4 degrees. \\'I\\'m not even sure people would \\nbe able to feel that difference,\\' he said. Any such plan, \\nhowever, would likely produce a gleam in the eyes of \\nJapan\\'s huge construction industry, known for its \\npropensity for public works projects. Although several are \\ndecried as wasteful, public works projects have long been \\nused by the government in attempts to stimulate the \\neconomy.  (((Nice use of the word \"attempts.\")))\\n\\n    \"Frankly, I think this plan is still really more of a \\ndream than anything else,\" Minobe said. \\n\\nO=c=O O=c=O O=c=O O=c=O\\nTOKYO STAYS COOL\\nAS DEADLY HEATWAVE BAKES \\nKOBE, OSAKA, KYOTO\\nO=c=O O=c=O O=c=O O=c=O\\n\\n\\n'\n",
    "emails = np.array([email], dtype='O')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5f668ec",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'message_from_string'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [51]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m emails_tr \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43memails\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\pipeline.py:658\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    656\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m--> 658\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36mEmailTransformer.transform\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     10\u001b[0m x_out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((x\u001b[38;5;241m.\u001b[39mshape), dtype\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(x):\n\u001b[1;32m---> 12\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[43memail\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessage_from_string\u001b[49m(e)\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrip_headers:\n\u001b[0;32m     15\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mkeys():\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'message_from_string'"
     ]
    }
   ],
   "source": [
    "emails_tr = pipeline.transform(emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73d911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
